{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "#### The purpose of this notebook is to experiment with predictive modeling on pre-processed run data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21632, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>accel_x</th><th>accel_y</th><th>accel_z</th><th>cadence_steps_per_minute</th><th>accel_magnitude_smoothed</th><th>target_speed_mps_smoothed</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.45491</td><td>0.162384</td><td>-0.308426</td><td>180.0</td><td>0.499111</td><td>0.7956</td></tr><tr><td>-0.440277</td><td>0.162308</td><td>-0.150299</td><td>180.0</td><td>0.483114</td><td>0.816</td></tr><tr><td>-0.33432</td><td>0.034775</td><td>-0.000259</td><td>180.0</td><td>0.502502</td><td>0.8364</td></tr><tr><td>-0.428482</td><td>-0.061768</td><td>-0.045181</td><td>180.0</td><td>0.581293</td><td>0.8568</td></tr><tr><td>-0.55397</td><td>-0.204468</td><td>-0.327637</td><td>180.0</td><td>0.695047</td><td>0.8772</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ accel_x   â”† accel_y   â”† accel_z   â”† cadence_steps_per_ â”† accel_magnitude_sm â”† target_speed_mps_s â”‚\n",
       "â”‚ ---       â”† ---       â”† ---       â”† minute             â”† oothed             â”† moothed            â”‚\n",
       "â”‚ f64       â”† f64       â”† f64       â”† ---                â”† ---                â”† ---                â”‚\n",
       "â”‚           â”†           â”†           â”† f64                â”† f64                â”† f64                â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ -0.45491  â”† 0.162384  â”† -0.308426 â”† 180.0              â”† 0.499111           â”† 0.7956             â”‚\n",
       "â”‚ -0.440277 â”† 0.162308  â”† -0.150299 â”† 180.0              â”† 0.483114           â”† 0.816              â”‚\n",
       "â”‚ -0.33432  â”† 0.034775  â”† -0.000259 â”† 180.0              â”† 0.502502           â”† 0.8364             â”‚\n",
       "â”‚ -0.428482 â”† -0.061768 â”† -0.045181 â”† 180.0              â”† 0.581293           â”† 0.8568             â”‚\n",
       "â”‚ -0.55397  â”† -0.204468 â”† -0.327637 â”† 180.0              â”† 0.695047           â”† 0.8772             â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "features_path = \"../data-processed/run_data_1-16-26_processed.parquet\"\n",
    "features = [\"accel_x\", \"accel_y\", \"accel_z\", \"cadence_steps_per_minute\", \"accel_magnitude_smoothed\"]\n",
    "target = \"target_speed_mps_smoothed\"\n",
    "window_size_hz = 50 # 50 rows at 50 Hz = 1 second\n",
    "\n",
    "df = pl.read_parquet(features_path).select(features + [target])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (17305, 5)\n",
      "Train targets shape: (17305, 1)\n",
      "Val features shape: (4277, 5)\n",
      "Val targets shape: (4277, 1)\n"
     ]
    }
   ],
   "source": [
    "from gait_analytics.model.utils import train_val_split_data\n",
    "\n",
    "train, val, feature_scaler, target_scaler = train_val_split_data(df, features, target, window_size=window_size_hz)\n",
    "\n",
    "train_features, train_targets = train\n",
    "val_features, val_targets = val\n",
    "\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "print(f\"Train targets shape: {train_targets.shape}\")\n",
    "\n",
    "print(f\"Val features shape: {val_features.shape}\")\n",
    "print(f\"Val targets shape: {val_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17256, 5, 50)\n",
      "y_train shape: (17256, 1)\n",
      "\n",
      "X_val shape: (4228, 5, 50)\n",
      "y_val shape: (4228, 1)\n"
     ]
    }
   ],
   "source": [
    "from gait_analytics.model.utils import create_cnn_windows\n",
    "\n",
    "stride = 1\n",
    "\n",
    "X_train, y_train = create_cnn_windows(train_features, train_targets, features, window_size=window_size_hz, stride=stride)\n",
    "X_val, y_val = create_cnn_windows(val_features, val_targets, features, window_size=window_size_hz, stride=stride)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"\\nX_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | FLOPs\n",
      "----------------------------------------------------\n",
      "0 | model   | GaitNet | 44.8 K | train | 0    \n",
      "1 | loss_fn | MSELoss | 0      | train | 0    \n",
      "----------------------------------------------------\n",
      "44.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.8 K    Total params\n",
      "0.179     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:02<00:00, 199.56it/s, v_num=0, train_loss=0.0166, val_loss=0.809]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:02<00:00, 199.01it/s, v_num=0, train_loss=0.0166, val_loss=0.809]\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as lit\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gait_analytics.model.gait_lit_module import GaitDataset, GaitLightingModel\n",
    "from gait_analytics.model.gait_model import GaitNet\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_dataset = GaitDataset(X_train, y_train)\n",
    "test_dataset = GaitDataset(X_val, y_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = GaitNet(input_channels=len(features))\n",
    "lit_model = GaitLightingModel(model=model, learning_rate=learning_rate) \n",
    "\n",
    "logger = TensorBoardLogger(\"logs\", name=\"cnn_gait_model\")\n",
    "trainer = lit.Trainer(max_epochs=10, accelerator=\"auto\", logger=logger)\n",
    "\n",
    "trainer.fit(lit_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
